{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abe3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # TensorFlow kütüphanesini içe aktarıyoruz.\n",
    "from keras.preprocessing.image import ImageDataGenerator  # Görüntü verilerini artırmak ve işlemek için kullanılan sınıf.\n",
    "from tensorflow.keras.models import Sequential  # Model oluşturmak için kullanılan Sequential sınıfı.\n",
    "from tensorflow.keras import datasets, layers, models  # TensorFlow'dan gerekli modüller.\n",
    "import matplotlib.pyplot as plt  # Grafikler oluşturmak için kullanılan kütüphane.\n",
    "import os  # İşletim sistemi ile ilgili işlemler için kullanılan kütüphane.\n",
    "import numpy as np  # Sayısal işlemler ve veri yönetimi için kullanılan kütüphane.\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # CNN katmanları için gerekli modüller.\n",
    "from keras.optimizers import Adam  # Model optimizasyonu için Adam optimizasyon algoritması.\n",
    "from keras.losses import mean_squared_error  # Kayıp fonksiyonu olarak \"mean_squared_error\" kullanımı.\n",
    "from keras.metrics import mean_squared_error  # Değerlendirme metriği olarak \"mean_squared_error\" kullanımı.\n",
    "import cv2  # Görüntü işleme için kullanılan OpenCV kütüphanesi.\n",
    "import matplotlib.pyplot as plt  # Görselleştirme için matplotlib kütüphanesi tekrar çağrılmış (tekrarlanan çağrı gereksizdir).\n",
    "from PIL import Image  # Görüntü işleme için Python Imaging Library (Pillow).\n",
    "from keras.applications.inception_v3 import preprocess_input  # InceptionV3 modeli için gerekli ön işleme fonksiyonu.\n",
    "from keras.preprocessing import image  # Görüntü işlemede yardımcı olan fonksiyonlar.\n",
    "from tensorflow.keras.preprocessing import image  # TensorFlow versiyonu da kullanılmış (aynı işlevsellik için iki farklı çağrı yapılmış, gereksiz tekrar).\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # Eğitim sırasında erken durdurma için kullanılan sınıf.\n",
    "from tensorflow.keras.models import load_model  # Kaydedilmiş modelleri yüklemek için kullanılan fonksiyon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d51bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10538 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Eğitim veri artırma (data augmentation) işlemi\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, # Görüntü piksel değerlerini 0-1 aralığına ölçeklendirir.\n",
    "                                  shear_range = 0.2, # Görüntülere kaydırma (shear) işlemi uygular.\n",
    "                                  zoom_range = 0.2, # Görüntülere rastgele yakınlaştırma uygular.\n",
    "                                  horizontal_flip = True) # Görüntüleri yatay olarak rastgele çevirir.\n",
    "\n",
    "# Eğitim verilerini belirtilen klasörden okuyarak ve veri artırma işlemleri uygulayar\n",
    "training_set = train_datagen.flow_from_directory(r\"C:\\Users\\kalybeai\\Desktop\\Sunstorm Analysis System\\masked_continuum\\train\", # Eğitim verilerinin bulunduğu klasör.\n",
    "                                                target_size=(256,256), # Görüntülerin yeniden boyutlandırılacağı hedef boyutlar (256x256 piksel).\n",
    "                                                batch_size = 32, # Her bir eğitim turunda (epoch) modele aynı anda verilecek 32 görüntülük grup.\n",
    "                                                class_mode ='categorical') # Sınıflar arasında kategorik sınıflandırma yapılacağını belirtir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ed7053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2522 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Test verilerindeki piksel değerlerini 0-1 aralığına ölçeklendirir.\n",
    "\n",
    "# Test verilerini belirtilen klasörden alıp modele değerlendirme için uygun hale getiriyor.\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    r\"C:\\\\Users\\\\kalybeai\\\\Desktop\\\\Sunstorm Analysis System\\\\masked_continuum\\\\test\",  # Test verilerinin bulunduğu klasör.\n",
    "    target_size=(256, 256),  # Görüntülerin yeniden boyutlandırılacağı hedef boyutlar (256x256 piksel).\n",
    "    batch_size=32,  # Her bir test grubunda modele aynı anda verilecek 32 görüntülük grup.\n",
    "    class_mode='categorical'  # Sınıflar arasında kategorik sınıflandırma yapılacağını belirtir.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532abda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN modeli tanımlanıyor.\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),  # İlk evrişim katmanı, 32 filtre kullanıyor ve giriş boyutunu tanımlıyor.\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Havuzlama katmanı, boyutları küçültmek için 2x2 filtre kullanıyor.\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # İkinci evrişim katmanı, 64 filtre kullanıyor.\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # İkinci havuzlama katmanı.\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # Üçüncü evrişim katmanı, 128 filtre kullanıyor.\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Üçüncü havuzlama katmanı.\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu'),  # Dördüncü evrişim katmanı, 256 filtre kullanıyor.\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Dördüncü havuzlama katmanı.\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu'),  # Beşinci evrişim katmanı, 256 filtre kullanıyor.\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Beşinci havuzlama katmanı.\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu'),  # Altıncı evrişim katmanı, 512 filtre kullanıyor.\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Altıncı havuzlama katmanı.\n",
    "\n",
    "    Flatten(),  # 2D verileri tek boyutlu bir vektöre dönüştürüyor.\n",
    "    Dense(512, activation='relu'),  # Tam bağlantılı katman, 512 nöron içeriyor.\n",
    "    Dropout(0.5),  # Aşırı öğrenmeyi önlemek için %50 dropout uyguluyor.\n",
    "\n",
    "    Dense(256, activation='relu'),  # 256 nöronlu tam bağlantılı bir başka katman.\n",
    "    Dropout(0.5),  # %50 dropout uyguluyor.\n",
    "\n",
    "    Dense(128, activation='relu'),  # 128 nöronlu tam bağlantılı katman.\n",
    "    Dropout(0.5),  # %50 dropout uyguluyor.\n",
    "\n",
    "    Dense(2, activation='softmax')  # Çıkış katmanı, 2 sınıf için softmax aktivasyonu kullanıyor.\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e855356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin derlenmesi (compile) işlemi yapılıyor.\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # Optimizasyon algoritması olarak Adam kullanılıyor ve öğrenme oranı 0.0001 olarak ayarlanıyor.\n",
    "    loss='categorical_crossentropy',  # Çok sınıflı sınıflandırma için kullanılan kayıp fonksiyonu.\n",
    "    metrics=['accuracy']  # Modelin performansını doğruluk (accuracy) metriği ile değerlendirin.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8f15dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,372,226\n",
      "Trainable params: 3,372,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modelin özet bilgilerini yazdırır.\n",
    "model.summary()  # Modelin katmanlarını, parametre sayısını ve çıkış şekillerini gösterir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f072177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim sırasında aşırı öğrenmeyi önlemek ve gereksiz eğitimden kaçınmak için erken durdurma (early stopping) callback'i tanımlanıyor.\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)  # Eğitim sırasında kayıp (loss) değerini izler, 5 epoch boyunca iyileşme olmazsa eğitimi durdurur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ec6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelin eğitim süreci başlatılıyor.\n",
    "model.fit(\n",
    "    training_set,  # Eğitim için kullanılan veri kümesi.\n",
    "    epochs=50,  # Eğitim süreci için maksimum epoch sayısı.\n",
    "    batch_size=16,  # Her bir batch'te kullanılacak veri miktarı.\n",
    "    callbacks=[early_stopping]  # Eğitim sırasında erken durdurma işlemini sağlayan callback.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef334e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin test veri seti üzerindeki performansı değerlendirilir.\n",
    "evaluation = model.evaluate(test_set)  # Test veri setinde loss (kayıp) ve accuracy (doğruluk) hesaplar.\n",
    "print(\"Test Loss:\", evaluation[0])  # Test setindeki kayıp değerini yazdırır.\n",
    "print(\"Test Accuracy:\", evaluation[1])  # Test setindeki doğruluk değerini yazdırır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"continuum_cnn1.h5\")  # Eğitilen model dosya olarak kaydediliyor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
